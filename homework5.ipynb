{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dBi-MfNgG9IB"
      },
      "source": [
        "## Домашняя работа #5.\n",
        "\n",
        "**Kaggle: [competition](https://www.kaggle.com/competitions/hse-2023-hw-5), [invite link](https://www.kaggle.com/t/6d51db6f2dde497a9c12ecf28899082f)**\n",
        "\n",
        "### Описание\n",
        "\n",
        "Вам предоставлен измененный датасет CIFAR10. В нём содержится 50+10 тысяч RGB изображений размера 32х32 следующих 10 классов: airplane, automobile, bird, cat, deer, dog, frog, horse, ship, truck.\n",
        "\n",
        "Задача: используя свёрточные нейронные сети, добиться максимальной точности классификации.\n",
        "\n",
        "### Данные\n",
        "\n",
        "В данном ноутбуке уже есть код для PyTorch, отвечающий за загрузку данных. Если будете использовать этот фреймворк, можно пропустить секцию. Если же хочется использовать другой фреймворк глубокого обучения, ниже дано краткое описание формата хранения данных.\n",
        "\n",
        "Каждый из файлов — сериализованный с помощью pickle c 4ой версией протолока python-словарик.\n",
        "\n",
        "Список файлов:\n",
        "\n",
        "- `meta` — метаданные датасета (например, названия классов)\n",
        "- `data_train` — данные обучения, 50к примеров, по 5к на один класс\n",
        "- `data_test` — данные теста, 10к примеров, по 1к на один класс, без ground-truth классов\n",
        "\n",
        "Словарики с данными имеют следующие поля:\n",
        "\n",
        "- `section` — имя части данных (обучение/тест)\n",
        "- `names` — хеш-идентификаторы объекта\n",
        "- `labels` — ground-truth классы, список из N чисел от 0 до 9\n",
        "- `images` — numpy массив размером `(N, 3*32*32)` с изображениями\n",
        "\n",
        "### Оценка\n",
        "\n",
        "Качество решения будет оцениваться по метрике \"точность\". Точность – это количество правильно классифицированных картинок к общему числу картинок в тестовом наборе. Публичный лидерборд рассчитывается по 30% тестовых данных, поэтому старайтесь не переобучаться под него.\n",
        "\n",
        "```\n",
        "accuracy = (correct classified) / (total # of examples)\n",
        "```\n",
        "\n",
        "В качестве решения вы должны прислать файл формата:\n",
        "\n",
        "```\n",
        "Id,Category\n",
        "0, 3\n",
        "1, 2\n",
        "2, 9\n",
        "3, 1\n",
        "...\n",
        "```\n",
        "\n",
        "где:\n",
        "\n",
        "- `Id` — порядковый номер объекта в тестовом датасете\n",
        "- `Category` — предсказанный класс объекта\n",
        "\n",
        "В данном ноутбуке уже есть код, подготавливающий файл решения.\n",
        "\n",
        "Итоговая оценка складывается из двух:\n",
        "- по 5 баллов за преодоление каждого из бенчмарков (от 0 до 15 баллов)\n",
        "- от 0 до 15 баллов за сам код решения\n",
        "\n",
        "### Эксперименты\n",
        "\n",
        "Так как в обучении нейросетевой модели есть очень много различных гиперпараметров, в данном домашнем задании нужно будет делать много различных экспериментов. И будет очень полезно, и для вас самих, и для нас, проверяющих, наличие текстового описания всех, или по крайней мере самых интересных / важных в выборе итоговой модели, экспериментов с результатами в финальном ноутбуке. Наличие и подробность описания экспериментов будут входить в итоговую оценку за домашнее задание. Дедлайн на Kaggle специально поставлен немного раньше, чтобы у вас было время спокойно дописать отчет об экспериментах."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jm6VSsdbG9IK"
      },
      "source": [
        "## Решение"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nWUgESjqG9IL"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import trange\n",
        "from IPython.display import clear_output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wxvsuhDsG9IO"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pickle\n",
        "from typing import Any, Callable, Optional, Tuple\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I67MDMgqG9IQ"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from torchvision.transforms import ToTensor, Compose\n",
        "from torchvision.datasets.vision import VisionDataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WZHrDghiG9IR"
      },
      "source": [
        "Данные лежат в секции [Data](https://www.kaggle.com/c/csc-cv21-hw5/data) kaggle-соревнования. <br>\n",
        "Нужно скачать архив с данными и расспаковать его. <br>\n",
        "В переменной ниже надо указать путь до датасета. <br>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4NztdwC4G9IS"
      },
      "outputs": [],
      "source": [
        "dataset_root = \"data/\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KKklLnOuG9IT"
      },
      "source": [
        "Код для загрузки измененного датасета CIFAR10. Аргументы инициализации:\n",
        "\n",
        "- `root` — строка, путь до директории с файлами датасета\n",
        "- `train` — флаг, загружать часть для обучения или теста\n",
        "- `transform` — преобразования изображения\n",
        "- `target_transform` — преобразования класса изображения"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qRFxlpiCG9IT"
      },
      "outputs": [],
      "source": [
        "class CIFAR10(VisionDataset):\n",
        "\n",
        "    def __init__(self,\n",
        "                 root: str,\n",
        "                 train: bool = True,\n",
        "                 transform: Optional[Callable] = None,\n",
        "                 target_transform: Optional[Callable] = None,\n",
        "                 ) -> None:\n",
        "\n",
        "        super().__init__(root, transform=transform, target_transform=target_transform)\n",
        "        self.train = train\n",
        "\n",
        "        meta_path = os.path.join(self.root, 'meta')\n",
        "        with open(meta_path, \"rb\") as f:\n",
        "            content = pickle.load(f)\n",
        "            self.classes = content['label_names']\n",
        "            self.class_to_idx = {_class: i for i, _class in enumerate(self.classes)}\n",
        "\n",
        "        data_path = os.path.join(self.root, 'data_train' if train else 'data_test')\n",
        "        with open(data_path, \"rb\") as f:\n",
        "            content = pickle.load(f)\n",
        "            self.data = content['images'].reshape(-1, 3, 32, 32).transpose((0, 2, 3, 1))\n",
        "            self.targets = content.get('labels')\n",
        "\n",
        "    def __getitem__(self, index: int) -> Tuple[Any, Any]:\n",
        "        img = Image.fromarray(self.data[index])\n",
        "        target = self.targets[index] if self.targets else len(self.classes)\n",
        "        if self.transform is not None:\n",
        "            img = self.transform(img)\n",
        "        if self.target_transform is not None:\n",
        "            target = self.target_transform(target)\n",
        "        return img, target\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        return len(self.data)\n",
        "\n",
        "    def extra_repr(self) -> str:\n",
        "        split = \"Train\" if self.train is True else \"Test\"\n",
        "        return f\"Split: {split}\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lg_a30x0G9IW"
      },
      "source": [
        "### Загрузка датасета"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ix4gzjwiG9IW"
      },
      "source": [
        "Загружаем часть датасета для обучения."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tP3muPkoG9IX"
      },
      "outputs": [],
      "source": [
        "data = CIFAR10(\n",
        "    root=dataset_root,\n",
        "    train=True,\n",
        "    transform=ToTensor(),\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X8lF96VKG9IY"
      },
      "source": [
        "Разбиваем случайным образом датасет на обучение и валидацию. <br>\n",
        "На первой части будем обучать модель классификации. <br>\n",
        "На второй части будем оценивать качество во время экспериментов. <br>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OIpJTW_cG9IZ"
      },
      "outputs": [],
      "source": [
        "train_data, val_data = torch.utils.data.random_split(\n",
        "    data,\n",
        "    [40000, 10000],\n",
        "    generator=torch.Generator().manual_seed(42),\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jZ5iJsI5G9IZ"
      },
      "source": [
        "Инициализируем data loader-ы."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kbOao5e0G9Ia"
      },
      "outputs": [],
      "source": [
        "batch_size = 64\n",
        "train_dataloader = DataLoader(train_data, batch_size=batch_size)\n",
        "val_dataloader = DataLoader(val_data, batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dv2vksflG9Ia"
      },
      "source": [
        "Посмотрим, какой размерности батчи выдает data loader."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XzFCXqL3G9Ib"
      },
      "outputs": [],
      "source": [
        "for X, y in train_dataloader:\n",
        "    print(\"Shape of X [N, C, H, W]: \", X.shape)\n",
        "    print(\"Shape of y: \", y.shape, y.dtype)\n",
        "    break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hmKECcBTG9Ie"
      },
      "source": [
        "### Модель классификации"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "80PZjHHjG9If"
      },
      "source": [
        "Определяем, на каком устройстве будем обучать модель."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9SJwrIM4G9If",
        "outputId": "9b4fed74-466e-402a-8d62-259891202f22"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using cuda device\n"
          ]
        }
      ],
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Using {} device\".format(device))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oiUEcmjrMSOY"
      },
      "source": [
        "Train-test loops"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "258RitI2L6fZ"
      },
      "outputs": [],
      "source": [
        "import IPython\n",
        "from math import ceil\n",
        "from tqdm import tqdm\n",
        "\n",
        "def train_loop(model, dataloader, loss_fn, optimizer, step=0.05, history_loss=None, history_acc=None):\n",
        "    out = display(IPython.display.Pretty('Learning...'), display_id=True)\n",
        "\n",
        "    size = len(dataloader.dataset)\n",
        "    len_size = len(str(size))\n",
        "    batches = ceil(size / dataloader.batch_size) - 1\n",
        "\n",
        "    train_acc, train_loss = [], []\n",
        "    percentage = 0\n",
        "\n",
        "    for batch, (X, y) in enumerate(tqdm(dataloader, leave=False, desc=\"Batch #\")):\n",
        "        X, y = X.to(device), y.to(device)\n",
        "\n",
        "        pred=model.forward(X)\n",
        "        loss=loss_fn(pred,y)\n",
        "\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if batch / batches > percentage or batch == batches:\n",
        "            out.update(f'[{int(percentage * size)}/{size}] Loss: {loss:>8f}')\n",
        "            percentage += step\n",
        "\n",
        "    if history_loss is not None:\n",
        "        history_loss.append(np.mean(train_loss))\n",
        "    if history_acc is not None:\n",
        "        history_acc.append(np.mean(train_acc))\n",
        "\n",
        "    return {'train_loss': np.mean(train_loss), 'train_acc': np.mean(train_acc)} #TO DO\n",
        "\n",
        "def test_loop(model, dataloader, loss_fn, history_loss=None, history_acc=None):\n",
        "\n",
        "    size = len(dataloader.dataset)\n",
        "    test_loss, correct = 0, 0\n",
        "    batches = ceil(size / dataloader.batch_size)\n",
        "\n",
        "    val_loss, val_acc = [], []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for X,y in dataloader:\n",
        "            X,y=X.to(device), y.to(device)\n",
        "            pred=model.forward(X)\n",
        "            cur_loss=loss_fn(pred,y).item()\n",
        "            test_loss+=cur_loss\n",
        "            val_loss.append(cur_loss)\n",
        "\n",
        "            cur_cor=(pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "            correct+=cur_cor\n",
        "            val_acc.append(cur_cor)\n",
        "\n",
        "    test_loss /= batches\n",
        "    correct /= size\n",
        "\n",
        "    print(f\"Validation accuracy: {(100*correct):>0.1f}%, Validation loss: {test_loss:>8f} \\n\")\n",
        "\n",
        "    if history_loss is not None:\n",
        "        history_loss.append(np.mean(val_loss))\n",
        "    if history_acc is not None:\n",
        "        history_acc.append(np.mean(val_acc))\n",
        "\n",
        "    return {'val_loss': np.mean(val_loss), 'val_acc': np.mean(val_acc)}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2HiQD7zZG9Ig"
      },
      "source": [
        "Задаем архитектуру модели классификации. <br>\n",
        "Тут большой простор для разных экспериментов. <br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Awz69-H56jXX"
      },
      "source": [
        "Сначала я опробовал ResNet18. Реализацию которого я уже делал в процессе другого курса."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FvECgqTB6bym"
      },
      "outputs": [],
      "source": [
        "class ResidualBlock(nn.Module):\n",
        "     def __init__(self, in_channels, out_channels):\n",
        "         super().__init__()\n",
        "         stride = (2, 2) if in_channels != out_channels else (1, 1)\n",
        "\n",
        "         self.shortcut=nn.Sequential(\n",
        "              nn.Conv2d(in_channels, out_channels, kernel_size=(1, 1),stride=stride, bias=False),\n",
        "              nn.BatchNorm2d(out_channels)\n",
        "         )\n",
        "\n",
        "         self.activation=nn.ReLU()\n",
        "         self.conv1=nn.Conv2d(in_channels=in_channels, out_channels=out_channels,\n",
        "                                kernel_size=(3, 3), padding=(1, 1), stride=stride, bias=False)\n",
        "         self.conv2 = nn.Conv2d(in_channels=out_channels, out_channels=out_channels,\n",
        "                                kernel_size=(3, 3), padding=(1, 1), stride=(1, 1), bias=False)\n",
        "         self.bn1 = nn.BatchNorm2d(num_features=out_channels)\n",
        "         self.bn2 = nn.BatchNorm2d(num_features=out_channels)\n",
        "\n",
        "\n",
        "     def forward(self, x):\n",
        "\n",
        "         residual = self.shortcut(x)\n",
        "         x = self.activation(self.bn1(self.conv1(x)))\n",
        "         x = self.bn2(self.conv2(x))\n",
        "\n",
        "         return x + residual\n",
        "\n",
        "\n",
        "class ResNetLayer(nn.Module):\n",
        "\n",
        "     def __init__(self, in_channels, out_channels):\n",
        "         super().__init__()\n",
        "         self.blocks = nn.Sequential(ResidualBlock(in_channels, out_channels),\n",
        "                                     ResidualBlock(out_channels, out_channels))\n",
        "\n",
        "\n",
        "     def forward(self, x):\n",
        "         x = self.blocks(x)\n",
        "         return x\n",
        "\n",
        "\n",
        "class ResNet18(nn.Module):\n",
        "     def __init__(self, in_channels=3, n_classes=10):\n",
        "         super().__init__()\n",
        "         self.conv1=nn.Conv2d(in_channels, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "         self.conv2=nn.Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "         self.conv3=nn.Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "         self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "\n",
        "         self.bn1 = nn.BatchNorm2d(64)\n",
        "         self.activation = nn.ReLU()\n",
        "\n",
        "         self.layers = nn.Sequential(\n",
        "                     ResNetLayer(64, 64),\n",
        "                     ResNetLayer(64, 128),\n",
        "                     ResNetLayer(128, 256),\n",
        "                     ResNetLayer(256, 512),\n",
        "                )\n",
        "         self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "         self.fc = nn.Linear(512, n_classes)\n",
        "         self.LogSoftmax = nn.LogSoftmax()\n",
        "\n",
        "\n",
        "     def forward(self, x):\n",
        "         x = self.maxpool(self.conv3(self.conv2(self.conv1(x))))\n",
        "         x = self.layers(x)\n",
        "         x = self.avgpool(x)\n",
        "         x = x.view(x.size(0), -1)\n",
        "         x = self.LogSoftmax(self.fc(x))\n",
        "\n",
        "\n",
        "         return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r8lGtmI9G9Ig"
      },
      "outputs": [],
      "source": [
        "model = ResNet18().to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aAJBXarE8nUe"
      },
      "source": [
        "В результате обучения на 30 эпохах с оптимизатором Adam и кросс-энтропией в качестве функции потерь, итоговая точность (accuracy) составила около 80%"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DLGpoCA994Z4"
      },
      "source": [
        "Далее я стал использовать предобученные сетки. На них (да и в целом нужно), важно использовать предобработку изображений, как минимум рескейл в тот размер, на котором училась сетка, а также нормализацию."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3qotKxN1FdEi"
      },
      "source": [
        "Я пробовал VGG-16BN и разные версии EfficientNet. Суть работы над ними была одинаковая, далее расскажу про EffNet, так как на нем получился итоговый результат."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v-gI9Tc4FtJE"
      },
      "source": [
        "В качетсве трансформации использовалась функция *torchvision.models.EfficientNet_B0_Weights.IMAGENET1K_V1.transforms()*,\n",
        "благодаря которой изображение ресайзится до размера 256, потом применяется кроп размера 224, а затем изображение нормализуется со средними (0.485, 0.456, 0.406) and стандартными отклонениями (0.229, 0.224, 0.225). Если посчитать по датасету, то получаются примерно такие же значения.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9B7eYivZHY0i"
      },
      "source": [
        "В итоге бралась предобученная модель и менялась только лишь голова -- последний слой. Обучался лишь он."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VQsudcoQHi_2"
      },
      "outputs": [],
      "source": [
        "from torchvision.models import efficientnet_b0, EfficientNet_B0_Weights\n",
        "\n",
        "eff_net = efficientnet_b0(weights=EfficientNet_B0_Weights)\n",
        "\n",
        "for param in eff_net.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "\n",
        "eff_net.classifier[1]=nn.Linear(in_features=1280, out_features=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jOKAhOAcJDCZ"
      },
      "source": [
        "Такой подход не позволил добится точности выше 80%. Поэтому далее попробовал обучать всю сетку, но с низким learning rate = 1e-5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-XuPmCftKE_Q"
      },
      "outputs": [],
      "source": [
        "eff_net = efficientnet_b0(weights=EfficientNet_B0_Weights)\n",
        "\n",
        "eff_net.classifier[1]=nn.Linear(in_features=1280, out_features=10)\n",
        "eff_net = eff_net.to(device)\n",
        "\n",
        "optimized_params = []\n",
        "for param in eff_net.parameters():\n",
        "    if param.requires_grad:\n",
        "        optimized_params.append(param)\n",
        "\n",
        "optimizer = torch.optim.Adam(optimized_params, lr=1e-5)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "epochs = 5\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    print(f\"Epoch {epoch+1}\\n-------------------------------\")\n",
        "    train_loop(model, train_dataloader, loss_fn, optimizer)\n",
        "    test_loop(model, test_dataloader, loss_fn)\n",
        "    torch.save(model.state_dict(), 'model.pth')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Omg6a_1UN2Hl"
      },
      "source": [
        "В результате точность уже на третей эпохе достигла 0.95, чего было для меня достаточно (оставалось мало времени, да и так достаточно близко к точности человека)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iZ-Tyj3-G9Im"
      },
      "source": [
        "### Отправка решения"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_PtkIkUsG9Im"
      },
      "source": [
        "Загружаем часть датасета для теста."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZrogskJDG9Im"
      },
      "outputs": [],
      "source": [
        "test_data = CIFAR10(\n",
        "    root=dataset_root,\n",
        "    train=False,\n",
        "    transform=ToTensor(),\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XTREMaKBG9Io"
      },
      "outputs": [],
      "source": [
        "test_dataloader = DataLoader(\n",
        "    test_data,\n",
        "    batch_size=batch_size,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i63WwoOdG9Io"
      },
      "source": [
        "Делаем предсказания итоговой моделью."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bYVwjcUYG9Io"
      },
      "outputs": [],
      "source": [
        "predictions = []\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    for X, _ in test_dataloader:\n",
        "        X = X.to(device)\n",
        "        pred = model(X).argmax(1).cpu().numpy()\n",
        "        predictions.extend(list(pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uViY1xXtG9Ip"
      },
      "source": [
        "Формируем файл решения для отправки в kaggle."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pO4QZrCgG9Ip"
      },
      "outputs": [],
      "source": [
        "def write_solution(filename, labels):\n",
        "    with open(filename, 'w') as solution:\n",
        "        print('Id,Category', file=solution)\n",
        "        for i, label in enumerate(labels):\n",
        "            print(f'{i},{label}', file=solution)\n",
        "\n",
        "write_solution('solution.csv', predictions)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
